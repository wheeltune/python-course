{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\"\n",
    "data_frame = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : re : 2 . 882 s - &gt; np np &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : s - &gt; np + np the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : 2 . 882 s - &gt; np np . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : gent conference \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : query : causatives in korean could a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                                msg\n",
       "0    ham  Subject : re : 2 . 882 s - > np np > date : su...\n",
       "1    ham  Subject : s - > np + np the discussion of s - ...\n",
       "2    ham  Subject : 2 . 882 s - > np np . . . for me it ...\n",
       "3    ham  Subject : gent conference \" for the listserv \"...\n",
       "4    ham  Subject : query : causatives in korean could a..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(data_frame[\"msg\"]), np.array(data_frame[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "        self.feature_category_count = defaultdict(int)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        self.feature_count = 0\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_train : list of str\n",
    "            содержит список (сообщений). слова в сообщении должны быть разделены пробелом.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        self.category_doc_counts.update(y_train)\n",
    "        \n",
    "        x_train = np.array(list(\n",
    "            map(lambda message: np.unique(message.split()), x_train)))\n",
    "        \n",
    "        for (document, cat) in zip(x_train, y_train):\n",
    "            self.feature_category_counts[cat].update(document)\n",
    "            self.feature_category_count[cat] = \\\n",
    "                sum(list(self.feature_category_counts[cat].values()))\n",
    "            self.feature_counts.update(document)\n",
    "        self.feature_count = sum(list(self.feature_counts.values()))\n",
    "        \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if self.category_priors is None:\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            self.category_priors = defaultdict(float)\n",
    "            for cat in self.get_categories():\n",
    "                self.category_priors[cat] = sum(y_train == cat) / len(y_train)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        texts = self.tokenize(text)\n",
    "        \n",
    "        categories = []\n",
    "        for text in texts:\n",
    "            categories.append(\n",
    "                self.get_categories()[np.argmax(self.get_probs(text))])\n",
    "\n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : list of float\n",
    "            Массив с точностями предсказаний точность предсказания.\n",
    "        \"\"\"\n",
    "        texts = self.tokenize(text)\n",
    "        \n",
    "        categories = np.array(self.predict(text))\n",
    "        labels = np.array(labels)\n",
    "        acc = sum(categories == labels) / len(labels)\n",
    "            \n",
    "        return acc\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        # Токенизируем текст, если это необходимо\n",
    "        text = self.tokenize(text)[0]\n",
    "            \n",
    "        probs = []\n",
    "        for cat in self.get_categories():\n",
    "            probs.append(self.get_category_prob(cat, text))\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятности принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        log_prob = np.log(self.category_priors[cat]) \\\n",
    "            + sum(list(map(lambda word: np.log(self.get_weighted_feature_prob(cat, word)), text)))\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        if feature in self.feature_counts:\n",
    "            prob = (self.weight \\\n",
    "                    * (self.feature_counts[feature] / self.feature_count \\\n",
    "                    + (self.feature_category_counts[cat][feature] \\\n",
    "                       / self.feature_category_count[cat]))) \\\n",
    "                / (self.weight + 1)\n",
    "        else:\n",
    "            return 0.5\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        cat_list = list(self.category_doc_counts.keys())\n",
    "        return cat_list\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        Токенизирует тексты, если это необходимо\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texts : list of list of str | list of srt\n",
    "            Возвращает токенизированные тексты.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            texts = [ text.split() ]\n",
    "        elif isinstance(text[0], str):\n",
    "            if np.any(list(map(lambda element: \" \" in element, text))):\n",
    "                texts = list(map(lambda document: document.split(), text))\n",
    "            else:\n",
    "                texts = [ text ]\n",
    "        else:\n",
    "            texts = text\n",
    "            \n",
    "        return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "class NLTKData:\n",
    "    def __init__(self, vocabulary, text):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.text = text\n",
    "        self.words = set(text)\n",
    "    \n",
    "    def items(self):\n",
    "        items = []\n",
    "        for word in self.vocabulary:\n",
    "            items.append((word, word in self.words))\n",
    "        return items\n",
    "    \n",
    "    def keys(self):\n",
    "        return list(self.vocabulary)\n",
    "    \n",
    "    def copy(self):\n",
    "        return NLTKData(self.vocabulary, self.text)\n",
    "        \n",
    "class NLTKCreator:\n",
    "    def __init__(self, texts):\n",
    "        self.vocabulary = set()\n",
    "        for text in texts:\n",
    "            self.vocabulary.update(text)\n",
    "    \n",
    "    def create(self, text):\n",
    "        return NLTKData(self.vocabulary, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = list(map(lambda doc: doc.lower().split(), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_creator = NLTKCreator(X_tokens)\n",
    "X_nltk = np.array(list(map(nltk_creator.create, X_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1695d75f8434c5eb5ea4c9e87a540e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLTK) [Fold 0]: 0.9517241379310345\n",
      "(NLTK) [Fold 1]: 0.9517241379310345\n",
      "(NLTK) [Fold 2]: 0.9655172413793104\n",
      "(NLTK) [Fold 3]: 0.9653979238754326\n",
      "(NLTK) [Fold 4]: 0.9584775086505191\n",
      "(NLTK) [Fold 5]: 0.9619377162629758\n",
      "(NLTK) [Fold 6]: 0.9480968858131488\n",
      "(NLTK) [Fold 7]: 0.916955017301038\n",
      "(NLTK) [Fold 8]: 0.9619377162629758\n",
      "(NLTK) [Fold 9]: 0.9653979238754326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "kf = KFold(len(y), n_folds=10, shuffle=True, random_state=24)\n",
    "\n",
    "nltk_accuracy = []\n",
    "for k, (train_index, test_index) in tqdm_notebook(enumerate(kf)):\n",
    "    nb = NaiveBayesClassifier.train(zip(X_nltk[train_index], y[train_index]))\n",
    "    \n",
    "    cat = list(map(nb.classify, X_nltk[test_index]))\n",
    "    nltk_accuracy.append(accuracy_score(cat, y[test_index]))\n",
    "    print(\"(NLTK) [Fold {}]: {}\".format(k, nltk_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5d41046bc240b4987b0bf29da8e02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NaiveBayes) [Fold 0]: 0.9448275862068966\n",
      "(NaiveBayes) [Fold 1]: 0.9344827586206896\n",
      "(NaiveBayes) [Fold 2]: 0.9517241379310345\n",
      "(NaiveBayes) [Fold 3]: 0.972318339100346\n",
      "(NaiveBayes) [Fold 4]: 0.9411764705882353\n",
      "(NaiveBayes) [Fold 5]: 0.9411764705882353\n",
      "(NaiveBayes) [Fold 6]: 0.9584775086505191\n",
      "(NaiveBayes) [Fold 7]: 0.9757785467128027\n",
      "(NaiveBayes) [Fold 8]: 0.972318339100346\n",
      "(NaiveBayes) [Fold 9]: 0.9515570934256056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "kf = KFold(len(y), n_folds=10, shuffle=True, random_state=24)\n",
    "\n",
    "naive_accuracy = []\n",
    "for k, (train_index, test_index) in tqdm_notebook(enumerate(kf)):    \n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X[train_index], y[train_index])\n",
    "    naive_accuracy.append(nb.score(X[test_index], y[test_index]))\n",
    "    print(\"(NaiveBayes) [Fold {}]: {}\".format(k, naive_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<your code here>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
